{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet -U pip\n!pip install --quiet -U openai-whisper\n!pip install feedparser\n!pip install --quiet -U sentence-transformers\n!apt-get update && apt install -y ffmpeg","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-04-27T12:44:40.966747Z","iopub.execute_input":"2023-04-27T12:44:40.967586Z","iopub.status.idle":"2023-04-27T12:46:13.403975Z","shell.execute_reply.started":"2023-04-27T12:44:40.967538Z","shell.execute_reply":"2023-04-27T12:46:13.402727Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting feedparser\n  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sgmllib3k (from feedparser)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=0a5a9714d2f66fee59e1b3c09368bd7aca20db1037dabc6d8ac4d135a0734320\n  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\nSuccessfully built sgmllib3k\nInstalling collected packages: sgmllib3k, feedparser\nSuccessfully installed feedparser-6.0.10 sgmllib3k-1.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\nGet:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [5002 B]\nGet:2 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]       \nGet:3 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [2217 B]\nGet:4 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [430 kB]\nHit:5 http://archive.ubuntu.com/ubuntu focal InRelease                        \nGet:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\nGet:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1036 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3150 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2341 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1334 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\nGet:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2644 kB]\nGet:15 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\nGet:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2170 kB]\nFetched 13.5 MB in 4s (3249 kB/s)                            \nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n0 upgraded, 0 newly installed, 0 to remove and 70 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall whisper\n!pip install --force-reinstall openai-whisper==20230124","metadata":{"execution":{"iopub.status.busy":"2023-04-27T12:56:57.868697Z","iopub.execute_input":"2023-04-27T12:56:57.869200Z","iopub.status.idle":"2023-04-27T12:59:42.355266Z","shell.execute_reply.started":"2023-04-27T12:56:57.869154Z","shell.execute_reply":"2023-04-27T12:59:42.352576Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting openai-whisper==20230124\n  Downloading openai-whisper-20230124.tar.gz (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting numpy (from openai-whisper==20230124)\n  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch (from openai-whisper==20230124)\n  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tqdm (from openai-whisper==20230124)\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting more-itertools (from openai-whisper==20230124)\n  Using cached more_itertools-9.1.0-py3-none-any.whl (54 kB)\nCollecting transformers>=4.19.0 (from openai-whisper==20230124)\n  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper==20230124)\n  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nCollecting future (from ffmpeg-python==0.2.0->openai-whisper==20230124)\n  Downloading future-0.18.3.tar.gz (840 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting filelock (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\nCollecting huggingface-hub<1.0,>=0.11.0 (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting packaging>=20.0 (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyyaml>=5.1 (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting regex!=2019.12.17 (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting importlib-metadata (from transformers>=4.19.0->openai-whisper==20230124)\n  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\nCollecting typing-extensions (from torch->openai-whisper==20230124)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20230124)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20230124)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20230124)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20230124)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230124)\n  Using cached setuptools-67.7.2-py3-none-any.whl (1.1 MB)\nCollecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230124)\n  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\nCollecting fsspec (from huggingface-hub<1.0,>=0.11.0->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting zipp>=0.5 (from importlib-metadata->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\nCollecting charset-normalizer<4,>=2 (from requests->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (171 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.0/171.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna<4,>=2.5 (from requests->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting certifi>=2017.4.17 (from requests->transformers>=4.19.0->openai-whisper==20230124)\n  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper, future\n  Building wheel for openai-whisper (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179329 sha256=39bc083ba1a68093f5bd949b1b5a9c65ea66e989f36ec5951ac882a6c3636c59\n  Stored in directory: /root/.cache/pip/wheels/40/d8/63/8683505dd95123899b99ee3a36c06a09a42f1998fe79a42fcd\n  Building wheel for future (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492036 sha256=04ce68be72b0af8701a108bbfa261894cb884062d16b441fe88c16db27604d1e\n  Stored in directory: /root/.cache/pip/wheels/fa/cd/1f/c6b7b50b564983bf3011e8fc75d06047ddc50c07f6e3660b00\nSuccessfully built openai-whisper future\nInstalling collected packages: tokenizers, zipp, wheel, urllib3, typing-extensions, tqdm, setuptools, regex, pyyaml, packaging, nvidia-cuda-nvrtc-cu11, numpy, more-itertools, idna, future, fsspec, filelock, charset-normalizer, certifi, requests, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, importlib-metadata, ffmpeg-python, nvidia-cudnn-cu11, huggingface-hub, transformers, torch, openai-whisper\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.2\n    Uninstalling tokenizers-0.13.2:\n      Successfully uninstalled tokenizers-0.13.2\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.11.0\n    Uninstalling zipp-3.11.0:\n      Successfully uninstalled zipp-3.11.0\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.38.4\n    Uninstalling wheel-0.38.4:\n      Successfully uninstalled wheel-0.38.4\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.14\n    Uninstalling urllib3-1.26.14:\n      Successfully uninstalled urllib3-1.26.14\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Uninstalling typing_extensions-4.4.0:\n      Successfully uninstalled typing_extensions-4.4.0\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.63.0\n    Uninstalling tqdm-4.63.0:\n      Successfully uninstalled tqdm-4.63.0\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 59.8.0\n    Uninstalling setuptools-59.8.0:\n      Successfully uninstalled setuptools-59.8.0\n  Attempting uninstall: regex\n    Found existing installation: regex 2021.11.10\n    Uninstalling regex-2021.11.10:\n      Successfully uninstalled regex-2021.11.10\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0\n    Uninstalling PyYAML-6.0:\n      Successfully uninstalled PyYAML-6.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.6\n    Uninstalling numpy-1.21.6:\n      Successfully uninstalled numpy-1.21.6\n  Attempting uninstall: more-itertools\n    Found existing installation: more-itertools 9.1.0\n    Uninstalling more-itertools-9.1.0:\n      Successfully uninstalled more-itertools-9.1.0\n  Attempting uninstall: idna\n    Found existing installation: idna 3.4\n    Uninstalling idna-3.4:\n      Successfully uninstalled idna-3.4\n  Attempting uninstall: future\n    Found existing installation: future 0.18.3\n    Uninstalling future-0.18.3:\n      Successfully uninstalled future-0.18.3\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.1.0\n    Uninstalling fsspec-2023.1.0:\n      Successfully uninstalled fsspec-2023.1.0\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.9.0\n    Uninstalling filelock-3.9.0:\n      Successfully uninstalled filelock-3.9.0\n  Attempting uninstall: charset-normalizer\n    Found existing installation: charset-normalizer 2.1.1\n    Uninstalling charset-normalizer-2.1.1:\n      Successfully uninstalled charset-normalizer-2.1.1\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2022.12.7\n    Uninstalling certifi-2022.12.7:\n      Successfully uninstalled certifi-2022.12.7\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.2\n    Uninstalling requests-2.28.2:\n      Successfully uninstalled requests-2.28.2\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.11.4\n    Uninstalling importlib-metadata-4.11.4:\n      Successfully uninstalled importlib-metadata-4.11.4\n  Attempting uninstall: ffmpeg-python\n    Found existing installation: ffmpeg-python 0.2.0\n    Uninstalling ffmpeg-python-0.2.0:\n      Successfully uninstalled ffmpeg-python-0.2.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.13.3\n    Uninstalling huggingface-hub-0.13.3:\n      Successfully uninstalled huggingface-hub-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.27.4\n    Uninstalling transformers-4.27.4:\n      Successfully uninstalled transformers-4.27.4\n  Attempting uninstall: torch\n    Found existing installation: torch 1.13.0+cpu\n    Uninstalling torch-1.13.0+cpu:\n      Successfully uninstalled torch-1.13.0+cpu\n  Attempting uninstall: openai-whisper\n    Found existing installation: openai-whisper 20230306\n    Uninstalling openai-whisper-20230306:\n      Successfully uninstalled openai-whisper-20230306\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiohttp 3.8.3 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.1.0 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\nbayesian-optimization 1.4.2 requires colorama>=0.4.6, but you have colorama 0.4.4 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 6.6.0 which is incompatible.\nconfection 0.0.4 requires typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 6.6.0 which is incompatible.\ngoogle-cloud-dlp 3.11.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-pubsub 2.14.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-resource-manager 1.8.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-spanner 3.27.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\nibis-framework 2.1.1 requires importlib-metadata<5,>=4; python_version < \"3.8\", but you have importlib-metadata 6.6.0 which is incompatible.\nibis-framework 2.1.1 requires regex<2022.0.0,>=2021.7.6, but you have regex 2022.10.31 which is incompatible.\njupyter-console 6.6.3 requires jupyter-core!=5.0.*,>=4.12, but you have jupyter-core 4.11.1 which is incompatible.\nlibrosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\npandas-profiling 3.6.2 requires requests<2.29,>=2.24.0, but you have requests 2.29.0 which is incompatible.\npandas-profiling 3.6.2 requires tqdm<4.65,>=4.48.2, but you have tqdm 4.65.0 which is incompatible.\npydocstyle 6.3.0 requires importlib-metadata<5.0.0,>=2.0.0; python_version < \"3.8\", but you have importlib-metadata 6.6.0 which is incompatible.\nspacy 3.5.1 requires typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\ntensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\nthinc 8.1.9 requires typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\ntorchaudio 0.13.0+cpu requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\ntorchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\ntorchvision 0.14.0+cpu requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\nwasabi 1.1.1 requires typing-extensions<4.5.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed certifi-2022.12.7 charset-normalizer-3.1.0 ffmpeg-python-0.2.0 filelock-3.12.0 fsspec-2023.1.0 future-0.18.3 huggingface-hub-0.14.1 idna-3.4 importlib-metadata-4.2.0 more-itertools-9.1.0 numpy-1.21.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 openai-whisper-20230124 packaging-23.0 pyyaml-6.0 regex-2022.10.31 requests-2.29.0 setuptools-67.7.2 tokenizers-0.13.3 torch-1.13.1 tqdm-4.64.1 transformers-4.28.1 typing-extensions-4.4.0 urllib3-1.26.15 wheel-0.40.0 zipp-3.11.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.signal import argrelextrema\nimport math\n\nimport whisper\n\nimport feedparser\nimport urllib.request\n\n### transcription model ###\nmodel_size = \"large-v2\"\n\nprint('Loading transcription model...')\n# Run on GPU with FP16\nmodel = whisper.load_model(model_size) #, device=\"cuda\")\n# or run on GPU with INT8\n# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n# or run on CPU with INT8\n# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\nprint('Done.')\n\n### paragraph model ###\nprint('Loading word embedding model...')\nsentencemodel = SentenceTransformer('all-mpnet-base-v2')\nprint('Done.')\n\ndef rev_sigmoid(x:float)->float:\n    return (1 / (1 + math.exp(0.5*x)))\n    \ndef activate_similarities(similarities:np.array, p_size=10)->np.array:\n        \"\"\" Function returns list of weighted sums of activated sentence similarities\n        Args:\n            similarities (numpy array): it should square matrix where each sentence corresponds to another with cosine similarity\n            p_size (int): number of sentences are used to calculate weighted sum \n        Returns:\n            list: list of weighted sums\n        \"\"\"\n        # To create weights for sigmoid function we first have to create space. P_size will determine number of sentences used and the size of weights vector.\n        x = np.linspace(-10,10,p_size)\n        # Then we need to apply activation function to the created space\n        y = np.vectorize(rev_sigmoid) \n        # Because we only apply activation to p_size number of sentences we have to add zeros to neglect the effect of every additional sentence and to match the length ofvector we will multiply\n        activation_weights = np.pad(y(x),(0,similarities.shape[0]-p_size))\n        ### 1. Take each diagonal to the right of the main diagonal\n        diagonals = [similarities.diagonal(each) for each in range(0,similarities.shape[0])]\n        ### 2. Pad each diagonal by zeros at the end. Because each diagonal is different length we should pad it with zeros at the end\n        diagonals = [np.pad(each, (0,similarities.shape[0]-len(each))) for each in diagonals]\n        ### 3. Stack those diagonals into new matrix\n        diagonals = np.stack(diagonals)\n        ### 4. Apply activation weights to each row. Multiply similarities with our activation.\n        diagonals = diagonals * activation_weights.reshape(-1,1)\n        ### 5. Calculate the weighted sum of activated similarities\n        activated_similarities = np.sum(diagonals, axis=0)\n        return activated_similarities\n\ndef paragraphise(bigstring):\n    sentences = bigstring.split('. ')\n    \n    embeddings = sentencemodel.encode(sentences, show_progress_bar=False)\n    similarities = cosine_similarity(embeddings)\n    activated_similarities = activate_similarities(similarities, p_size=5)\n    minimas = argrelextrema(activated_similarities, np.less, order=2) #order parameter controls how frequent should be splits. I would not reccomend changing this parameter.\n\n    split_points = [each for each in minimas[0]]\n    text = ''\n    for num,each in enumerate(sentences):\n        if num in split_points:\n            text+=f'\\n\\n {each}. '\n        else:\n            text+=f'{each}. '\n    return text\n\n### other functions ### \ndef zfill_alternative(x,l=2): return x if len(x) >= l else '0'*(l-len(x))+x","metadata":{"execution":{"iopub.status.busy":"2023-04-27T13:02:20.411773Z","iopub.execute_input":"2023-04-27T13:02:20.412807Z","iopub.status.idle":"2023-04-27T13:02:57.634961Z","shell.execute_reply.started":"2023-04-27T13:02:20.412747Z","shell.execute_reply":"2023-04-27T13:02:57.633733Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loading transcription model...\nDone.\nLoading word embedding model...\nDone.\n","output_type":"stream"}]},{"cell_type":"code","source":"import feedparser\nimport urllib.request\nNewsFeed = feedparser.parse(\"https://tehnikarechi.studio/api/rss/podcasts/knizhnyy-bazar\")\nentry = NewsFeed.entries[0]\n\nprint(entry.keys())","metadata":{"execution":{"iopub.status.busy":"2023-04-27T13:03:26.994825Z","iopub.execute_input":"2023-04-27T13:03:26.995850Z","iopub.status.idle":"2023-04-27T13:03:29.630623Z","shell.execute_reply.started":"2023-04-27T13:03:26.995786Z","shell.execute_reply":"2023-04-27T13:03:29.629317Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"dict_keys(['title', 'title_detail', 'id', 'guidislink', 'links', 'link', 'summary', 'summary_detail', 'content', 'published', 'published_parsed', 'authors', 'author', 'author_detail', 'image', 'itunes_duration', 'subtitle', 'subtitle_detail', 'itunes_episodetype', 'tags', 'itunes_explicit'])\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir knizhnyy-bazar","metadata":{"execution":{"iopub.status.busy":"2023-04-26T20:39:22.833755Z","iopub.execute_input":"2023-04-26T20:39:22.834174Z","iopub.status.idle":"2023-04-26T20:39:23.924798Z","shell.execute_reply.started":"2023-04-26T20:39:22.834118Z","shell.execute_reply":"2023-04-26T20:39:23.923448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"NewsFeed = feedparser.parse(\"https://tehnikarechi.studio/api/rss/podcasts/knizhnyy-bazar\")\n\ndl_dir = 'knizhnyy-bazar'\n\nfailsforsomereason = []\n\narr = os.listdir('/kaggle/working/'+dl_dir)\n\nfor entry in tqdm(NewsFeed.entries):\n    notdone = True\n    while notdone:\n        try:\n            vid_title = re.sub(r'[^A-Za-zЁёА-я0-9— ]+', '', entry['title'].replace(u'\\xa0', u' '))[:130]\n\n            if (vid_title in [x[:-4] for x in arr] or \n                vid_title in failsforsomereason):\n                notdone = False\n                continue\n\n            opener = urllib.request.build_opener()\n            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n            urllib.request.install_opener(opener)\n            urllib.request.urlretrieve(entry['links'][1]['href'], \"audio.mp3\")\n            print(vid_title)\n\n            #print(yt.streams.filter(only_audio=True).order_by('abr'))\n\n            transcription = model.transcribe(\"audio.mp3\",  language=\"ru\")\n            \n            prettytext = paragraphise(transcription['text'])\n\n            with open(dl_dir+'/'+vid_title+'.txt','w+',encoding='utf-8') as myfile:\n                myfile.write('---')\n                myfile.write('\\ntitle: '+vid_title)\n                myfile.write('\\nauthor: '+entry['author'])\n                myfile.write('\\npublished: '+entry['published'])\n                myfile.write('\\ntags: '+str([ a['term'] for a in entry['tags']]))\n                myfile.write('\\n---\\n\\n')\n                myfile.write(prettytext)\n            \n            print('Done')\n            notdone = False\n        except Exception as e:\n            continue","metadata":{"execution":{"iopub.status.busy":"2023-04-27T13:04:06.317234Z","iopub.execute_input":"2023-04-27T13:04:06.317676Z","iopub.status.idle":"2023-04-27T15:45:00.677078Z","shell.execute_reply.started":"2023-04-27T13:04:06.317638Z","shell.execute_reply":"2023-04-27T15:45:00.674186Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"  0%|          | 0/106 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Глава в которой Галя и Настя отвечают на ваши вопросы и спойлерят следующий сезон\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n 54%|█████▍    | 57/106 [2:40:50<2:18:15, 169.30s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3578593249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#print(yt.streams.filter(only_audio=True).order_by('abr'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"audio.mp3\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ru\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprettytext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraphise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscription\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_speech\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# save no_speech_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         return F.linear(\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"!tar -zcvf knizhnyy-bazar.tar.gz knizhnyy-bazar/*.txt","metadata":{"execution":{"iopub.status.busy":"2023-04-27T11:00:53.641663Z","iopub.execute_input":"2023-04-27T11:00:53.642728Z","iopub.status.idle":"2023-04-27T11:00:55.218576Z","shell.execute_reply.started":"2023-04-27T11:00:53.642688Z","shell.execute_reply":"2023-04-27T11:00:55.217342Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"knigtok/5 февраля начнется новый сезон Книжного базара — о книгах на которых мы все выросли Что перечитать Мы составили список.txt\nknigtok/Глава в которой Аэлиту съедает Чужой Пелевин обнуляет космос но всех спасает Илон Маск.txt\nknigtok/Глава в которой Бондарчук обыгрывает Толстого на Бородинском поле а Кубрик снимает лучший костюмный фильм в истории.txt\nknigtok/Глава в которой Властелин колец становится экоманифестом а Толкин оказывается Гретой Тунберг 1950х.txt\nknigtok/Глава в которой Галина Юзефович и Антон Долин возвращаются с сезоном об экранизациях — теперь с видеоверсией И начинают с Шерлока .txt\nknigtok/Глава в которой Галина Юзефович советует читать на каникулах детективы а Антон Долин отговаривает смотреть Реальную любовь.txt\nknigtok/Глава в которой Гамлет Фотоувеличение и даже Царь Эдип больше похожи на детектив чем сериал Шерлок.txt\nknigtok/Глава в которой Гарри Поттер становится Христом и навсегда входит в наш культурный код хотите вы этого или нет.txt\nknigtok/Глава в которой Гекльберри Финн изводит переводчиков и заставляет нас спорить о политкорректности.txt\nknigtok/Глава в которой Джеймс Бонд спорит со Штирлицем а побеждают братья Коэн Говорим о шпионских экранизациях в финале сезона.txt\nknigtok/Глава в которой Джейн Эйр оказывается романом о человеке у которого чердак не в порядке.txt\nknigtok/Глава в которой Дон Кихота можно увидеть в Веноме князе Мышкине и даже Гитлере.txt\nknigtok/Глава в которой Дракула превращается из средневекового кровопийцы в прогрессивного горожанина и даже открывает бизнес.txt\nknigtok/Глава в которой Звездные войны оказываются устаревшей фантастикой но современной семейной сагой.txt\nknigtok/Глава в которой Кира Найтли соревнуется с Татьяной Самойловой а Голливуд пытается снять Войну и мир без клюквы Выпуск о фильмах по.txt\nknigtok/Глава в которой Книжный базар The best заканчивается обсуждением детских страшилок жутких книг Гоголя и новых русских хорроров.txt\nknigtok/Глава в которой Король Лев оказывается Гамлетом Макбет становится японским самураем а Орсон Уэллс снимает Отелло в бане.txt\nknigtok/Глава в которой Маркес полтора года пьет виски и постепенно превращается в СалтыковаЩедрина.txt\nknigtok/Глава в которой Мастер и Маргарита превращается в young adult и оказывается смешнее 12 стульев.txt\nknigtok/Глава в которой Пелевина Сорокина и Сальникова плохо экранизируют и только Глуховскому везет.txt\nknigtok/Глава в которой Рассказ служанки оказывается идеальной антиутопией о настоящем а 1984 на ее фоне — всего лишь историческим романом.txt\nknigtok/Глава в которой Сомерсет Моэм оказывается шпионом пишет гадости про друзей и наживается на этом.txt\nknigtok/Глава в которой Три мушкетера с Боярским оказываются культовой но не лучшей экранизацией Дюма.txt\nknigtok/Глава в которой Харари и книги про пофигизм почти всех победили но тут случилась пандемия.txt\nknigtok/Глава в которой авторы бросились писать автофикшн но у многих получился пост в фейсбуке на который еще и друзья обиделись.txt\nknigtok/Глава в которой большой роман — это и Донна Тартт на 800 страниц и Джулиан Барнс на 200 Почему роман не обязан быть длинным.txt\nknigtok/Глава в которой в Книжном базаре снова появляется Гарри Поттер — и кажется на этот раз проигрывает Фантастическим тварям.txt\nknigtok/Глава в которой ведущие советуют книги на время самоизоляции и отговаривают читать классику про эпидемии.txt\nknigtok/Глава в которой все вспоминают про Довлатова только анекдоты а он оказывается самым грустным русским писателем.txt\nknigtok/Глава в которой герои Брэдбери смотрят ковер вместо телевизора а на них надвигается экономический кризис.txt\nknigtok/Глава в которой герои Ремарка выпивают два вермута три коньяка два рома а потом ведущие сбиваются со счета.txt\nknigtok/Глава в которой детектив умирает писатели копируют сюжеты друг у друга но всех спасает Джоан Роулинг.txt\nknigtok/Глава в которой дети рассказывают серьезные истории Они больше не аутсайдеры не милые крошки и носители хоррора а нормальные обычн.txt\nknigtok/Глава в которой издатели заново выпускают книги тридцатилетней давности а мы читаем их как новые.txt\nknigtok/Глава в которой летний сезон с Антоном Долиным о ужас заканчивается спором о хоррорах.txt\nknigtok/Глава в которой месть приносит Александру Дюма деньги славу и любовь советских читателей.txt\nknigtok/Глава в которой мы все застряли в подростковой культуре читаем Гарри Поттера слушаем Билли Айлиш — и радуемся.txt\nknigtok/Глава в которой новые книги оказываются старыми убийца снова дворецкий Ахилл опять побеждает Гектора — а мы снова почемуто этому у.txt\nknigtok/Глава в которой новый сезон Книжного базара начинается с обсуждения миллениальных романов какихкаких — книг без экшена которые нев.txt\nknigtok/Глава в которой писателям хочется вернуться в XIX век но газовых фонарей тумана и зловония уже не хватает чтобы создать хороший ро.txt\nknigtok/Глава в которой по всей Саге о Форсайтах развешаны ружья но ни одно не стреляет.txt\nknigtok/Глава в которой портрет Хемингуэя в свитере появляется в каждой семье и только у Насти Завозовой его нет.txt\nknigtok/Глава в которой разворачиваются новые скандалы в литературе — и не только вокруг Джоан Роулинг Имеет ли писатель право говорить о .txt\nknigtok/Глава в которой режиссеры все никак не справятся с Мастером и Маргаритой а лучший Булгаков в кино — до сих пор Иван Васильевич мен.txt\nknigtok/Глава в которой российское военное кино оказывается не хуже советского но читать кроме Василя Быкова попрежнему нечего.txt\nknigtok/Глава в которой фантастические упыри и единороги проникают в большую литературу но иногда ее только портят.txt\nknigtok/Глава в которой фильмы наконецто оказываются лучше книг — потому что это вестерны.txt\nknigtok/Глава в которой эльфы захватили большую литературу а фантастику перестали писать только для гиков Продолжаем сезон Книжный базар T.txt\nknigtok/Глава о Викторианской эпохе которая не дает покоя современным писателям и ведущим Книжного базара.txt\nknigtok/Глава о важных российских романах последних лет iPhuck 10 Золото бунта Манарага Заххок и не только — во втором эпизоде Книжного ба.txt\nknigtok/Глава о детективах Все что мы о них говорили за два года — теперь в одном эпизоде Да мы начинаем Книжный базар The best.txt\nknigtok/Глава о книгах для подростков и миллениалов Дети рассказывают взрослые истории а взрослые с упоением впадают в детство.txt\nknigtok/Новогодняя глава в которой Галина Юзефович и Антон Долин снова вместе обсуждают волшебные смешные и страшные сказки которые стоит .txt\nknigtok/Новогодняя глава в которой Терри Пратчетт и Дэн Браун соседствуют с Пушкиным и Толстым — в ответах Галины Юзефович и Антона Долина.txt\nknigtok/Прелесть чтения в том что в этом занятии нельзя облажаться В финале сезона отвечаем на ваши вопросы о важных книгах фанфиках и Игр.txt\nknigtok/Так всетаки фэнтези зашквар или нет Начинаем летний сезон Книжного базара с Антоном Долиным — в защиту стыдных жанров.txt\nknigtok/Финальный эпизод Книжного базара с Галиной Юзефович и Анастасией Завозовой Ведущие отвечают на ваши письма и прощаются возможно на.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'knizhnyy-bazar.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T11:00:59.403945Z","iopub.execute_input":"2023-04-27T11:00:59.405257Z","iopub.status.idle":"2023-04-27T11:00:59.414768Z","shell.execute_reply.started":"2023-04-27T11:00:59.405210Z","shell.execute_reply":"2023-04-27T11:00:59.413326Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/knigtok.tar.gz","text/html":"<a href='knigtok.tar.gz' target='_blank'>knigtok.tar.gz</a><br>"},"metadata":{}}]}]}