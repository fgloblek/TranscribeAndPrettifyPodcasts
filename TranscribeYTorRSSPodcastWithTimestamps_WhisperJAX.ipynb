{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup\n\nKaggle offers 20 hours of [TPU v3-8](https://www.kaggle.com/product-feedback/129828) usage per month for free, and this notebook requires it to run successfully. This is more than enough to download a podcast. We also import other dependencies. ","metadata":{}},{"cell_type":"code","source":"import jax\njax.devices()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U pip","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from whisper_jax import FlaxWhisperPipline\nimport jax.numpy as jnp\n\npipeline = FlaxWhisperPipline(\"openai/whisper-large-v2\", dtype=jnp.bfloat16, batch_size=16)\n#pipeline = FlaxWhisperPipline(\"openai/whisper-medium\", dtype=jnp.bfloat16, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jax.experimental.compilation_cache import compilation_cache as cc\n\ncc.initialize_cache(\"./jax_cache\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pytube","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test whether PyTube works correctly.","metadata":{}},{"cell_type":"code","source":"from pytube import YouTube\n\nvideo_url = 'https://www.youtube.com/watch?v=lT-YD_cm_SA'\nex = True\nwhile ex:\n    try:\n        yt = YouTube(video_url)\n        vid_title = yt.title\n        ex = False\n    except:\n        continue\n\naudio= yt.streams.filter(only_audio=True).order_by('abr').first().download(filename=\"audio.mp4\")\nprint(vid_title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport os\nimport pandas as pd\nfrom pytube import Playlist\nfrom tqdm import tqdm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, get ffmpeg to process .mp4 files. ","metadata":{}},{"cell_type":"code","source":"!apt-get update && apt install -y ffmpeg","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First model run\n\nAs detailed in the [Whisper-JAX](https://github.com/sanchit-gandhi/whisper-jax) repo, we need to compile the `pmap` function the first time. \n\n> You can expect compilation to take ~2 minutes on a TPU v3-8 with a batch size of 16. Enough time to grab a coffee ☕️\n\nSo let's do that. ","metadata":{}},{"cell_type":"code","source":"# JIT compile the forward call - slow, but we only do once\n%time text = pipeline(audio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transcribe a YouTube podcast\n\nWe transcribe the podcast [Brains and Gains by Dr. Dave Maconi](https://www.youtube.com/channel/UCW-PI9YMJ6SXPiqXy2FYfLg) about all things natural bodybuilding via its YouTube channel. \n\n","metadata":{}},{"cell_type":"code","source":"!mkdir BrainsAndGains","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PyTube tends to fail to fetch links, so a while loop is used. ","metadata":{}},{"cell_type":"code","source":"def zfill_alternative(x,l=2): return x if len(x) >= l else '0'*(l-len(x))+x\n\nc = Playlist('https://www.youtube.com/playlist?list=PL1WQINeRM1zeBpBpB-tnTDXIG5t4Wbbtf') # Brains\n\ndl_dir = 'BrainsAndGains'\n\n# Can catch exceptions but not implemented here. \nfailsforsomereason = []\n\narr = os.listdir('/kaggle/working/'+dl_dir)\n\nfor url in tqdm(c.video_urls):\n    notdone = True\n    while notdone:\n        try:\n            video_url = url\n            yt = YouTube(video_url)\n            \n            # Get the title and discard if already done.\n            vid_title = yt.title\n\n            if (vid_title in [x[:-3] for x in arr] or \n                re.sub(r'[^A-Za-z0-9 ]+', '', vid_title) in [x[:-3] for x in arr] or \n                vid_title in failsforsomereason):\n                notdone = False\n                continue\n            \n            # Download audio file. \n            audio_file = yt.streams.filter(only_audio=True).order_by('abr').first().download(filename=\"audio.mp4\")\n            print(vid_title)\n\n            # Transcribe. \n            transcription = pipeline(audio_file,  task=\"transcribe\", language=\"en\", return_timestamps=True)\n\n            # Take the 'chunks' and save as timestamp-text table. Finally save to .md\n            df = pd.DataFrame(transcription['chunks'], columns=['timestamp', 'text'])\n\n            df[['start','end']] = pd.DataFrame(df['timestamp'].tolist(), index=df.index)\n            df['minute'] = (df['start']//60).astype(int)\n            df['seconds'] = (df['start']-df.minute*60).astype(int)\n            df['time'] = '('+df.minute.astype(str).apply(zfill_alternative)+':'+df.seconds.astype(str).apply(zfill_alternative)+')'\n\n            dfgb = df.groupby(df.minute,as_index=False).text.agg(''.join)\n            dfmg = pd.merge(df,dfgb,on='minute')\n\n            dffirst = dfmg[['minute','time','text_y']].groupby(dfmg.minute,as_index=False).first()\n            dffirst = dffirst.rename(columns={'text_y':'text'})\n            dffirst[['time','text']].to_markdown( dl_dir+'/'+re.sub(r'[^A-Za-z0-9 ]+', '', vid_title)\n                                                +'.md',index=False)\n            \n            print('Done')\n            notdone = False\n        except Exception as e:\n            continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd BrainsAndGains && tar -zcvf BrainsAndGains.tar.gz *.md","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf BrainsAndGains.tar.gz BrainsAndGains/*.md","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display a clickable link to the tar file. ","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'BrainsAndGains.tar.gz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading from RSS feed\n\nThe second part looks at downloading from an RSS link. \n\nThe podcast in question is [Where Optimal Meets Practical](https://podcasts.apple.com/us/podcast/where-optimal-meets-practical/id1518859017) by Jordan Lips, also about natural bodybuilding (weird!). \n","metadata":{}},{"cell_type":"code","source":"import feedparser\nimport urllib.request\n\nNewsFeed = feedparser.parse(\"https://media.rss.com/whereoptimalmeetspractical/feed.xml\")\nentry = NewsFeed.entries[2]\n\nprint(entry.keys())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def zfill_alternative(x,l=2): return x if len(x) >= l else '0'*(l-len(x))+x\n\n\n#WOMP\nNewsFeed = feedparser.parse(\"https://media.rss.com/whereoptimalmeetspractical/feed.xml\")\n\ndl_dir = 'womp'\n\nfailsforsomereason = []\n\narr = os.listdir('/kaggle/working/'+dl_dir)\n\nfor entry in tqdm(NewsFeed.entries):\n    notdone = True\n    while notdone:\n        try:\n            vid_title = entry['title']\n\n\n            if (vid_title in [x[:-3] for x in arr] or \n                re.sub(r'[^A-Za-z0-9 ]+', '', vid_title) in [x[:-3] for x in arr] or \n                vid_title in failsforsomereason):\n                notdone = False\n                continue\n\n            opener = urllib.request.build_opener()\n            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n            urllib.request.install_opener(opener)\n            urllib.request.urlretrieve(entry['links'][1]['href'], audio_file)\n            print(vid_title)\n\n            #print(yt.streams.filter(only_audio=True).order_by('abr'))\n\n\n            transcription = pipeline(audio_file,  task=\"transcribe\", language=\"en\", return_timestamps=True)\n\n            df = pd.DataFrame(transcription['chunks'], columns=['timestamp', 'text'])\n\n            df[['start','end']] = pd.DataFrame(df['timestamp'].tolist(), index=df.index)\n\n\n            df['minute'] = (df['start']//60).astype(int)\n            df['seconds'] = (df['start']-df.minute*60).astype(int)\n\n            df['time'] = '('+df.minute.astype(str).apply(zfill_alternative)+':'+df.seconds.astype(str).apply(zfill_alternative)+')'\n\n            dfgb = df.groupby(df.minute,as_index=False).text.agg(''.join)\n            dfmg = pd.merge(df,dfgb,on='minute')\n\n            dffirst = dfmg[['minute','time','text_y']].groupby(dfmg.minute,as_index=False).first()\n            dffirst = dffirst.rename(columns={'text_y':'text'})\n\n            dffirst[['time','text']].to_markdown( dl_dir+'/'+re.sub(r'[^A-Za-z0-9 ]+', '', vid_title)\n                                                +'.md',index=False)\n            print('Done')\n            notdone = False\n        except Exception as e:\n            continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf womp.tar.gz womp/*.md","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'womp.tar.gz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}